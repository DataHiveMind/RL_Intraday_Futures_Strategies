# configs/experiment/ppo.yaml

inherit: base.yaml

agent:
  type: PPO
  hidden: [256, 256]
  gamma: 0.99
  lr: 0.0003
  clip_ratio: 0.2
  lam: 0.95
  batch_size: 128
  epochs: 10
training:
  episodes: 1000
